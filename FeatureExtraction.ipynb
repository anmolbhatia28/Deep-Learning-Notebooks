{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image features extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "from utils.data_utils import load_CIFAR10\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (10.0, 8.0) # set default size of plots\n",
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "plt.rcParams['image.cmap'] = 'gray'\n",
    "\n",
    "# for auto-reloading extenrnal modules\n",
    "# see http://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data\n",
    "Similar to previous exercises, we will load CIFAR-10 data from disk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_CIFAR10_data(num_training=49000, num_validation=1000, num_test=1000):\n",
    "  # Load the raw CIFAR-10 data\n",
    "  cifar10_dir = 'cs231n/datasets/cifar-10-batches-py'\n",
    "  X_train, y_train, X_test, y_test = load_CIFAR10(cifar10_dir)\n",
    "  \n",
    "  # Subsample the data\n",
    "  mask = range(num_training, num_training + num_validation)\n",
    "  X_val = X_train[mask]\n",
    "  y_val = y_train[mask]\n",
    "  mask = range(num_training)\n",
    "  X_train = X_train[mask]\n",
    "  y_train = y_train[mask]\n",
    "  mask = range(num_test)\n",
    "  X_test = X_test[mask]\n",
    "  y_test = y_test[mask]\n",
    "\n",
    "  return X_train, y_train, X_val, y_val, X_test, y_test\n",
    "\n",
    "X_train, y_train, X_val, y_val, X_test, y_test = get_CIFAR10_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract Features\n",
    "For each image computing a Histogram of Oriented\n",
    "Gradients (HOG) as well as a color histogram using the hue channel in HSV\n",
    "color space. Final feature vector for each image by concatenating\n",
    "the HOG and color histogram feature vectors.\n",
    "\n",
    "Roughly speaking, HOG should capture the texture of the image while ignoring\n",
    "color information, and the color histogram represents the color of the input\n",
    "image while ignoring texture.\n",
    "\n",
    "The `hog_feature` and `color_histogram_hsv` functions both operate on a single\n",
    "image and return a feature vector for that image. The extract_features\n",
    "function takes a set of images and a list of feature functions and evaluates\n",
    "each feature function on each image, storing the results in a matrix where\n",
    "each column is the concatenation of all feature vectors for a single image."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation of both the features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import numpy as np\n",
    "from scipy.ndimage import uniform_filter\n",
    "\n",
    "\n",
    "def extract_features(imgs, feature_fns, verbose=False):\n",
    "  \"\"\"\n",
    "  Given pixel data for images and several feature functions that can operate on\n",
    "  single images, apply all feature functions to all images, concatenating the\n",
    "  feature vectors for each image and storing the features for all images in\n",
    "  a single matrix.\n",
    "\n",
    "  Inputs:\n",
    "  - imgs: N x H X W X C array of pixel data for N images.\n",
    "  - feature_fns: List of k feature functions. The ith feature function should\n",
    "    take as input an H x W x D array and return a (one-dimensional) array of\n",
    "    length F_i.\n",
    "  - verbose: Boolean; if true, print progress.\n",
    "\n",
    "  Returns:\n",
    "  An array of shape (N, F_1 + ... + F_k) where each column is the concatenation\n",
    "  of all features for a single image.\n",
    "  \"\"\"\n",
    "  num_images = imgs.shape[0]\n",
    "  if num_images == 0:\n",
    "    return np.array([])\n",
    "\n",
    "  # Use the first image to determine feature dimensions\n",
    "  feature_dims = []\n",
    "  first_image_features = []\n",
    "  for feature_fn in feature_fns:\n",
    "    feats = feature_fn(imgs[0].squeeze())\n",
    "    assert len(feats.shape) == 1, 'Feature functions must be one-dimensional'\n",
    "    feature_dims.append(feats.size)\n",
    "    first_image_features.append(feats)\n",
    "\n",
    "  # Now that we know the dimensions of the features, we can allocate a single\n",
    "  # big array to store all features as columns.\n",
    "  total_feature_dim = sum(feature_dims)\n",
    "  imgs_features = np.zeros((num_images, total_feature_dim))\n",
    "  imgs_features[0] = np.hstack(first_image_features).T\n",
    "\n",
    "  # Extract features for the rest of the images.\n",
    "  for i in range(1, num_images):\n",
    "    idx = 0\n",
    "    for feature_fn, feature_dim in zip(feature_fns, feature_dims):\n",
    "      next_idx = idx + feature_dim\n",
    "      imgs_features[i, idx:next_idx] = feature_fn(imgs[i].squeeze())\n",
    "      idx = next_idx\n",
    "    if verbose and i % 1000 == 0:\n",
    "      print('Done extracting features for %d / %d images' % (i, num_images))\n",
    "\n",
    "  return imgs_features\n",
    "\n",
    "\n",
    "def rgb2gray(rgb):\n",
    "  \"\"\"Convert RGB image to grayscale\n",
    "\n",
    "    Parameters:\n",
    "      rgb : RGB image\n",
    "\n",
    "    Returns:\n",
    "      gray : grayscale image\n",
    "  \n",
    "  \"\"\"\n",
    "  return np.dot(rgb[...,:3], [0.299, 0.587, 0.144])\n",
    "\n",
    "\n",
    "def hog_feature(im):\n",
    "  \"\"\"Compute Histogram of Gradient (HOG) feature for an image\n",
    "  \n",
    "       Modified from skimage.feature.hog\n",
    "       http://pydoc.net/Python/scikits-image/0.4.2/skimage.feature.hog\n",
    "     \n",
    "     Reference:\n",
    "       Histograms of Oriented Gradients for Human Detection\n",
    "       Navneet Dalal and Bill Triggs, CVPR 2005\n",
    "     \n",
    "    Parameters:\n",
    "      im : an input grayscale or rgb image\n",
    "      \n",
    "    Returns:\n",
    "      feat: Histogram of Gradient (HOG) feature\n",
    "    \n",
    "  \"\"\"\n",
    "  \n",
    "  # convert rgb to grayscale if needed\n",
    "  if im.ndim == 3:\n",
    "    image = rgb2gray(im)\n",
    "  else:\n",
    "    image = np.at_least_2d(im)\n",
    "\n",
    "  sx, sy = image.shape # image size\n",
    "  orientations = 9 # number of gradient bins\n",
    "  cx, cy = (8, 8) # pixels per cell\n",
    "\n",
    "  gx = np.zeros(image.shape)\n",
    "  gy = np.zeros(image.shape)\n",
    "  gx[:, :-1] = np.diff(image, n=1, axis=1) # compute gradient on x-direction\n",
    "  gy[:-1, :] = np.diff(image, n=1, axis=0) # compute gradient on y-direction\n",
    "  grad_mag = np.sqrt(gx ** 2 + gy ** 2) # gradient magnitude\n",
    "  grad_ori = np.arctan2(gy, (gx + 1e-15)) * (180 / np.pi) + 90 # gradient orientation\n",
    "\n",
    "  n_cellsx = int(np.floor(sx / cx))  # number of cells in x\n",
    "  n_cellsy = int(np.floor(sy / cy))  # number of cells in y\n",
    "  # compute orientations integral images\n",
    "  orientation_histogram = np.zeros((n_cellsx, n_cellsy, orientations))\n",
    "  for i in range(orientations):\n",
    "    # create new integral image for this orientation\n",
    "    # isolate orientations in this range\n",
    "    temp_ori = np.where(grad_ori < 180 / orientations * (i + 1),\n",
    "                        grad_ori, 0)\n",
    "    temp_ori = np.where(grad_ori >= 180 / orientations * i,\n",
    "                        temp_ori, 0)\n",
    "    # select magnitudes for those orientations\n",
    "    cond2 = temp_ori > 0\n",
    "    temp_mag = np.where(cond2, grad_mag, 0)\n",
    "    orientation_histogram[:,:,i] = uniform_filter(temp_mag, size=(cx, cy))[cx/2::cx, cy/2::cy].T\n",
    "  \n",
    "  return orientation_histogram.ravel()\n",
    "\n",
    "\n",
    "def color_histogram_hsv(im, nbin=10, xmin=0, xmax=255, normalized=True):\n",
    "  \"\"\"\n",
    "  Compute color histogram for an image using hue.\n",
    "\n",
    "  Inputs:\n",
    "  - im: H x W x C array of pixel data for an RGB image.\n",
    "  - nbin: Number of histogram bins. (default: 10)\n",
    "  - xmin: Minimum pixel value (default: 0)\n",
    "  - xmax: Maximum pixel value (default: 255)\n",
    "  - normalized: Whether to normalize the histogram (default: True)\n",
    "\n",
    "  Returns:\n",
    "    1D vector of length nbin giving the color histogram over the hue of the\n",
    "    input image.\n",
    "  \"\"\"\n",
    "  ndim = im.ndim\n",
    "  bins = np.linspace(xmin, xmax, nbin+1)\n",
    "  hsv = matplotlib.colors.rgb_to_hsv(im/xmax) * xmax\n",
    "  imhist, bin_edges = np.histogram(hsv[:,:,0], bins=bins, density=normalized)\n",
    "  imhist = imhist * np.diff(bin_edges)\n",
    "\n",
    "  # return histogram\n",
    "  return imhist\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(49000, 32, 32, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\local\\Anaconda3-4.1.1-Windows-x86_64\\lib\\site-packages\\ipykernel\\__main__.py:118: VisibleDeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done extracting features for 1000 / 49000 images\n",
      "Done extracting features for 2000 / 49000 images\n",
      "Done extracting features for 3000 / 49000 images\n",
      "Done extracting features for 4000 / 49000 images\n",
      "Done extracting features for 5000 / 49000 images\n",
      "Done extracting features for 6000 / 49000 images\n",
      "Done extracting features for 7000 / 49000 images\n",
      "Done extracting features for 8000 / 49000 images\n",
      "Done extracting features for 9000 / 49000 images\n",
      "Done extracting features for 10000 / 49000 images\n",
      "Done extracting features for 11000 / 49000 images\n",
      "Done extracting features for 12000 / 49000 images\n",
      "Done extracting features for 13000 / 49000 images\n",
      "Done extracting features for 14000 / 49000 images\n",
      "Done extracting features for 15000 / 49000 images\n",
      "Done extracting features for 16000 / 49000 images\n",
      "Done extracting features for 17000 / 49000 images\n",
      "Done extracting features for 18000 / 49000 images\n",
      "Done extracting features for 19000 / 49000 images\n",
      "Done extracting features for 20000 / 49000 images\n",
      "Done extracting features for 21000 / 49000 images\n",
      "Done extracting features for 22000 / 49000 images\n",
      "Done extracting features for 23000 / 49000 images\n",
      "Done extracting features for 24000 / 49000 images\n",
      "Done extracting features for 25000 / 49000 images\n",
      "Done extracting features for 26000 / 49000 images\n",
      "Done extracting features for 27000 / 49000 images\n",
      "Done extracting features for 28000 / 49000 images\n",
      "Done extracting features for 29000 / 49000 images\n",
      "Done extracting features for 30000 / 49000 images\n",
      "Done extracting features for 31000 / 49000 images\n",
      "Done extracting features for 32000 / 49000 images\n",
      "Done extracting features for 33000 / 49000 images\n",
      "Done extracting features for 34000 / 49000 images\n",
      "Done extracting features for 35000 / 49000 images\n",
      "Done extracting features for 36000 / 49000 images\n",
      "Done extracting features for 37000 / 49000 images\n",
      "Done extracting features for 38000 / 49000 images\n",
      "Done extracting features for 39000 / 49000 images\n",
      "Done extracting features for 40000 / 49000 images\n",
      "Done extracting features for 41000 / 49000 images\n",
      "Done extracting features for 42000 / 49000 images\n",
      "Done extracting features for 43000 / 49000 images\n",
      "Done extracting features for 44000 / 49000 images\n",
      "Done extracting features for 45000 / 49000 images\n",
      "Done extracting features for 46000 / 49000 images\n",
      "Done extracting features for 47000 / 49000 images\n",
      "Done extracting features for 48000 / 49000 images\n",
      "(49000, 154)\n",
      "(1000, 154)\n"
     ]
    }
   ],
   "source": [
    "num_color_bins = 10 # Number of bins in the color histogram\n",
    "feature_fns = [hog_feature, lambda img: color_histogram_hsv(img, nbin=num_color_bins)]\n",
    "print(str(X_train.shape))\n",
    "X_train_feats = extract_features(X_train, feature_fns, verbose=True)\n",
    "print(str(X_train_feats.shape))\n",
    "X_val_feats = extract_features(X_val, feature_fns)\n",
    "print(str(X_val_feats.shape))\n",
    "X_test_feats = extract_features(X_test, feature_fns)\n",
    "\n",
    "# Preprocessing: Subtract the mean feature\n",
    "mean_feat = np.mean(X_train_feats, axis=0, keepdims=True)\n",
    "X_train_feats -= mean_feat\n",
    "X_val_feats -= mean_feat\n",
    "X_test_feats -= mean_feat\n",
    "\n",
    "# Preprocessing: Divide by standard deviation. This ensures that each feature\n",
    "# has roughly the same scale.\n",
    "std_feat = np.std(X_train_feats, axis=0, keepdims=True)\n",
    "X_train_feats /= std_feat\n",
    "X_val_feats /= std_feat\n",
    "X_test_feats /= std_feat\n",
    "\n",
    "# Preprocessing: Add a bias dimension\n",
    "X_train_feats = np.hstack([X_train_feats, np.ones((X_train_feats.shape[0], 1))])\n",
    "X_val_feats = np.hstack([X_val_feats, np.ones((X_val_feats.shape[0], 1))])\n",
    "X_test_feats = np.hstack([X_test_feats, np.ones((X_test_feats.shape[0], 1))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, use X_train_feats for training SVM or NN"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
